# Transactional Outbox

# Install

```
yarn infra
```

---

1 - Create Debezium connector config

```
POST: http://localhost:8083/connectors
{
"name": "mongo-connector",
"config": {
  "connector.class": "io.debezium.connector.mongodb.MongoDbConnector",
  "mongodb.connection.string": "mongodb://nestjs-microservice-primary:27017,nestjs-microservice-secondary:27017,nestjs-microservice-tertiary:27017/?replicaSet=app",
  "mongodb.hosts": "nestjs-microservice-primary:27017,nestjs-microservice-secondary:27017,nestjs-microservice-tertiary:27017",
  "mongodb.name": "dbserver1",
  "database.include.list": "order-db",
  "collection.include.list": "order-db.outbox",
  "tasks.max": "1",
  "topic.prefix": "dbz",
  "snapshot.mode": "initial",
  "transforms": "unwrap,setKey,customFilter",
  "transforms.unwrap.type": "io.debezium.connector.mongodb.transforms.ExtractNewDocumentState",
  "transforms.unwrap.drop.tombstones": "true",
  "transforms.unwrap.delete.handling.mode": "rewrite",
  "transforms.unwrap.remove.fields": "deletedAt,updatedAt,lastAttemptAt",
  "transforms.setKey.type": "org.apache.kafka.connect.transforms.ValueToKey",
  "transforms.setKey.fields": "aggregateId",
  "transforms.customFilter.type": "com.example.FilterRetryCountAndStatus",
  "key.converter": "org.apache.kafka.connect.json.JsonConverter",
  "value.converter": "org.apache.kafka.connect.json.JsonConverter",
  "key.converter.schemas.enable": "false",
  "value.converter.schemas.enable": "false",
  "topic.creation.groups": "dbz-order-db",
  "topic.creation.default.replication.factor": "1",
  "topic.creation.default.partitions": "1",
  "errors.tolerance": "all",
  "errors.log.enable": "true",
  "errors.deadletterqueue.topic.name": "dead-letter-topic",
  "errors.deadletterqueue.context.headers.enable": "true",
  "sanitize.field.names": "true",
  "database.history.logging.enabled": "true",
  "log.connection.messages": "true",
  "mongodb.log.connection": "true"
  }
}

```

‚úÖ Padr√£o Outbox

Utilizamos o padr√£o Outbox para garantir consist√™ncia entre opera√ß√µes de banco de dados e publica√ß√£o de mensagens Kafka. Cada evento √© persistido antes do envio, garantindo resili√™ncia e rastreabilidade.
üßµ Processamento ass√≠ncrono com Kafka

O servi√ßo consome mensagens do Kafka utilizando eachMessage com controle de heartbeat, evitando reprocessamento por falha de conex√£o. Em caso de falha cr√≠tica, o consumidor √© reinicializado automaticamente com disconnect() e connect().
üß† Circuit Breaker (com Opossum)

Implementamos um Circuit Breaker usando Opossum para evitar propaga√ß√£o de falhas em chamadas que acessam o dom√≠nio principal. Ele:

    Garante controle de falhas com fallback

    Emite eventos de estado (open, halfOpen, close)

    Possui timeout, resetTimeout, threshold configur√°veis

üîÅ Retry com backoff exponencial + jitter

Falhas com status retryable (como 5xx, 429, etc) s√£o tratadas com l√≥gica de exponential backoff com jitter, evitando sobrecarga nos servi√ßos downstream:

delay = baseDelay \* (2 \*\* retryCount) + jitter

O retry √© limitado a 5 tentativas.
üìä M√©tricas e observabilidade

Atrav√©s do MetricsService, s√£o registradas:

    Tentativas de retry por erro

    Interven√ß√µes manuais

    Estados do Circuit Breaker

    Casos de falha m√°xima (max retries)

üßØ Fallback e interven√ß√£o manual

Falhas que ultrapassam o limite de tentativas ou n√£o s√£o pass√≠veis de retry geram:

    Evento manual.intervention para operadores

    Evento retry.max_reached para filas de reprocessamento Ambos s√£o publicados em t√≥picos espec√≠ficos do Kafka para tratamento externo.

---

mas tem a oiutra tecnica onde eu abro uma transa√ß√£o, e so depois de tudo completo dentro dele eu commit, e tem o roollback no catch, no caso se der erro no kafka, ele iria para o rollback e cancelaria tudo, estou errado?
ChatGPT said:

Excelente racioc√≠nio, Mike! Voc√™ est√° quase certo, mas tem um detalhe crucial que faz a diferen√ßa aqui. Bora descer no detalhe:
üß† Teu racioc√≠nio:

    "Se eu abrir a transa√ß√£o do banco, fizer tudo (inclusive o envio Kafka) antes do commit(), e se der erro no Kafka, eu dou rollback() no banco ‚Äì ent√£o fica tudo certo, n√©?"

Resposta: Tecnicamente, sim... mas na pr√°tica, n√£o √© t√£o confi√°vel.
‚ö†Ô∏è O problema real est√° no que o Kafka faz por debaixo dos panos.

Vamos olhar um exemplo real com typeorm e Kafka:

const queryRunner = dataSource.createQueryRunner();
await queryRunner.startTransaction();

try {
await queryRunner.manager.save(pedido);

await kafka.send({ topic: 'pedido_criado', message: { ... } }); // <-- Aqui pode falhar

await queryRunner.commitTransaction(); // S√≥ chega aqui se tudo acima der certo
} catch (err) {
await queryRunner.rollbackTransaction(); // Se o Kafka falhar, rollback no banco
}

üß® O que pode dar errado aqui?

    Lat√™ncia ou timeout no Kafka: o envio pode ficar "pendurado", voc√™ faz rollback no banco, mas o Kafka j√° enviou mesmo assim (j√° foi pra rede).

    Acknowledge enganoso: mesmo com acks: all, o Kafka pode confirmar o envio, mas a mensagem pode estar numa parti√ß√£o offline e demorar a propagar.

    Erro ap√≥s envio: e se o kafka.send() for ass√≠ncrono e falhar depois que j√° foi pro wire? Voc√™ deu rollback achando que nada foi enviado, mas o consumidor j√° recebeu o evento.

Isso gera mensagens √≥rf√£s, ou pior, inconsist√™ncia dif√≠cil de rastrear.
üí° Compara√ß√£o com o Transactional Outbox:
Estrat√©gia Vantagem Risco
await sendKafka() antes do commit() Parece seguro e simples Kafka n√£o participa da transa√ß√£o ‚Üí poss√≠veis eventos "fantasmas"
Transactional Outbox Garante atomicidade de verdade Mais robusta, mas exige worker separado
‚úÖ Por isso o Transactional Outbox ainda √© o mais confi√°vel:

    Voc√™ nunca depende do Kafka estar 100% sincronizado com o commit do banco.

    Mesmo que o processo caia, o evento t√° salvo na tabela outbox e pode ser enviado depois.

    Pode garantir at-least-once delivery com retries e dead letter.

    √â resiliente a falhas parciais.

‚öôÔ∏è Quer algo mais pr√≥ximo disso?

O padr√£o que voc√™ descreveu √© semelhante ao chamado "Transactional Messaging" com manual commit, mas isso s√≥ √© realmente confi√°vel quando todos os participantes est√£o dentro da mesma transa√ß√£o distribu√≠da ‚Äî o que o Kafka n√£o suporta nativamente com bancos externos.

Se quiser, posso te mostrar como fazer isso de forma h√≠brida:

    typeorm + outbox_event table

    KafkaProducerService lendo e enviando

    Retry autom√°tico com marca√ß√£o de status no banco

Quer que eu monte esse esqueleto pra ti?
