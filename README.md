# Transactional Outbox

# Install

```
yarn infra
```

---

1 - Create Debezium connector config

```
POST: http://localhost:8083/connectors
{
"name": "mongo-connector",
"config": {
  "connector.class": "io.debezium.connector.mongodb.MongoDbConnector",
  "mongodb.connection.string": "mongodb://nestjs-microservice-primary:27017,nestjs-microservice-secondary:27017,nestjs-microservice-tertiary:27017/?replicaSet=app",
  "mongodb.hosts": "nestjs-microservice-primary:27017,nestjs-microservice-secondary:27017,nestjs-microservice-tertiary:27017",
  "mongodb.name": "dbserver1",
  "database.include.list": "order-db",
  "collection.include.list": "order-db.outbox",
  "tasks.max": "1",
  "topic.prefix": "dbz",
  "snapshot.mode": "initial",
  "transforms": "unwrap,setKey,customFilter",
  "transforms.unwrap.type": "io.debezium.connector.mongodb.transforms.ExtractNewDocumentState",
  "transforms.unwrap.drop.tombstones": "true",
  "transforms.unwrap.delete.handling.mode": "rewrite",
  "transforms.unwrap.remove.fields": "deletedAt,updatedAt,lastAttemptAt",
  "transforms.setKey.type": "org.apache.kafka.connect.transforms.ValueToKey",
  "transforms.setKey.fields": "aggregateId",
  "transforms.customFilter.type": "com.example.FilterRetryCountAndStatus",
  "key.converter": "org.apache.kafka.connect.json.JsonConverter",
  "value.converter": "org.apache.kafka.connect.json.JsonConverter",
  "key.converter.schemas.enable": "false",
  "value.converter.schemas.enable": "false",
  "topic.creation.groups": "dbz-order-db",
  "topic.creation.default.replication.factor": "1",
  "topic.creation.default.partitions": "1",
  "errors.tolerance": "all",
  "errors.log.enable": "true",
  "errors.deadletterqueue.topic.name": "dead-letter-topic",
  "errors.deadletterqueue.context.headers.enable": "true",
  "sanitize.field.names": "true",
  "database.history.logging.enabled": "true",
  "log.connection.messages": "true",
  "mongodb.log.connection": "true"
  }
}

```

‚úÖ Padr√£o Outbox

Utilizamos o padr√£o Outbox para garantir consist√™ncia entre opera√ß√µes de banco de dados e publica√ß√£o de mensagens Kafka. Cada evento √© persistido antes do envio, garantindo resili√™ncia e rastreabilidade.
üßµ Processamento ass√≠ncrono com Kafka

O servi√ßo consome mensagens do Kafka utilizando eachMessage com controle de heartbeat, evitando reprocessamento por falha de conex√£o. Em caso de falha cr√≠tica, o consumidor √© reinicializado automaticamente com disconnect() e connect().
üß† Circuit Breaker (com Opossum)

Implementamos um Circuit Breaker usando Opossum para evitar propaga√ß√£o de falhas em chamadas que acessam o dom√≠nio principal. Ele:

    Garante controle de falhas com fallback

    Emite eventos de estado (open, halfOpen, close)

    Possui timeout, resetTimeout, threshold configur√°veis

üîÅ Retry com backoff exponencial + jitter

Falhas com status retryable (como 5xx, 429, etc) s√£o tratadas com l√≥gica de exponential backoff com jitter, evitando sobrecarga nos servi√ßos downstream:

delay = baseDelay \* (2 \*\* retryCount) + jitter

O retry √© limitado a 5 tentativas.
üìä M√©tricas e observabilidade

Atrav√©s do MetricsService, s√£o registradas:

    Tentativas de retry por erro

    Interven√ß√µes manuais

    Estados do Circuit Breaker

    Casos de falha m√°xima (max retries)

üßØ Fallback e interven√ß√£o manual

Falhas que ultrapassam o limite de tentativas ou n√£o s√£o pass√≠veis de retry geram:

    Evento manual.intervention para operadores

    Evento retry.max_reached para filas de reprocessamento Ambos s√£o publicados em t√≥picos espec√≠ficos do Kafka para tratamento externo.
